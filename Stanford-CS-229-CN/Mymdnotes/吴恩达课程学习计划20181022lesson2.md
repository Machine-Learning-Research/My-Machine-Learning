#吴恩达课程学习计划lesson2
课程来源：网易公开课20节
主要参考资料：
1课程视频: 监督学习应用下降
2讲义notes2和ppt2
3黄海广笔记 
4相关code等

### 第二课内容：
### 线性回归
### 梯度下降
### 正规方程组

每个样本的正确答案是什么，让模型学习，产生更多的正确结果——监督学习
比如使用监督学习，让车实现自动驾驶，从人类司机那里学会一段路如何驾驶，即“正确驾驶方向”（神经网络———核心算法是梯度下降）。称其为回归问题是因为汽车预测表示行驶的方向的连续变量的值。

###1.学习第一个监督学习的例子：房价预测（线性假设）。###

1.**符号表示：**  
m表示训练样本的数量，比如：47个训练样本
x表示输入变量，也可以成为特征feature，比如：房子的大小
Y表示输出变量，也成为目标变量target，
（x，y）表示一个样本
第i个训练样本，或者表中的第i行，写成$(x^{(i)},y^{(i)})​$, i是上标，表示第几行。

 2.**训练样本提供给学习算法**  

 3.**之后学习算法会生成一个输出函数，用h表示——这个函数称之为“假设”**  
 4.**这个假设的任务，是接收“输入”，比如用一个新的住房面积作为x进行输入，输出新的y**  
 5.**问题的关键在于如何定义假设h

训练集合还可以加入其它特征，比如面积作为X1，房子房间的数量作为X2...  
h的形式以及参数$\theta$ 就是做出的假设 ，利用样本训练，学习到合适的参数值   
**n表示样本特征数量**  

6.**那么如何确定参数呢？  
$$
J(\theta)=\frac{1}{2}\sum_{i=1}^{m}(h_{\theta}(x^{(i)})-y^{(i)})^2
$$
在训练集上，使实际值和预测值的方差J尽可能的$minimize_{\theta}J( \theta)$。

接下来讲几个算法
搜索算法——先给参数向量一个初始值，不断地改变参数向量，使得J不不断变小。
往最陡的地方下降，使用梯度下降算法更新参数。


![梯度下降](/Users/zhengwenjiang/Desktop/梯度下降.png)  

###2.梯度下降的规则讲解(32min)  

**学习率控制学习速度**——手动设置  

这个算法叫做**批量梯度算法**，梯度下降算法的每一次迭代，都需要对遍历整个训练集合。  

如果m很大很大，那程序就要检测很多样本，这个时候就需要随机梯度下降算法（增量梯度x下降），会下降的很快，但是可能不会精确收敛到全局最小值。

定义参数梯度(51min)为一个向量 

####五个关键结论公式(59min)
###3.批量方程组(课程最后10min)
设计矩阵X的概念
y的向量定义和公式推导
####关于梯度下降具体可参考黄海广笔记P17-P29  
####多变量梯度下降黄海广笔记P38  
